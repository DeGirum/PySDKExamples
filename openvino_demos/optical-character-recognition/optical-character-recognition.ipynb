{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Character Recognition (OCR) with Degirum\n",
    "\n",
    "This tutorial demonstrates how to perform optical character recognition (OCR) with OpenVINO models. It is a continuation of the [hello-detection](../hello-detection/hello-detection.ipynb) tutorial, which shows only text detection.\n",
    "\n",
    "The [horizontal-text-detection-0001](https://docs.openvino.ai/2024/omz_models_model_horizontal_text_detection_0001.html) and [text-recognition-resnet](https://docs.openvino.ai/2024/omz_models_model_text_recognition_resnet_fc.html) models are used together for text detection and then text recognition.\n",
    "\n",
    "In this tutorial, Open Model Zoo tools including Model Downloader, Model Converter and Info Dumper are used to download and convert the models from [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo). For more information, refer to the [model-tools](../model-tools/model-tools.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify where you want to run your inferences, model_zoo_url, model name for OCR and image source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hw_location: where you want to run inference\n",
    "#     \"@cloud\" to use DeGirum cloud\n",
    "#     \"@local\" to run on local machine\n",
    "#     IP address for AI server inference\n",
    "# model_zoo_url: url/path for model zoo\n",
    "#     cloud_zoo_url: valid for @cloud, @local, and ai server inference options\n",
    "#     '': ai server serving models from local folder\n",
    "#     path to json file: single model zoo in case of @local inference\n",
    "# model_name: name of the model for running AI inference\n",
    "# image_source: image source for inference\n",
    "#     path to image file\n",
    "#     URL of image\n",
    "#     PIL image object\n",
    "#     numpy array\n",
    "\n",
    "hw_location = \"@cloud\"\n",
    "model_zoo_url = \"https://cs.degirum.com/degirum/timm_gender_model_test\"\n",
    "text_det_model_name = \"text_detection--704x704_float_openvino_cpu_1\"\n",
    "text_rec_model_name = \"resnet_text_recognition--704x704_float_openvino_cpu_1\"\n",
    "image_source = \"https://raw.githubusercontent.com/DeGirum/PySDKExamples/features/images/demo_text_det.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg, degirum_tools\n",
    "from postprocessor_ocr_det import OCRTextDetPostprocessor\n",
    "from preprocessor_ocr_rec import OCRTextRecPreprocessor\n",
    "from postprocessor_ocr_rec import OCRTextRecPostprocessor\n",
    "# Connect to AI inference engine\n",
    "# degirum_cloud_token: Degirum cloud API access token\n",
    "text_det_zoo = dg.connect(hw_location, model_zoo_url, degirum_tools.get_token())\n",
    "text_rec_zoo = dg.connect(hw_location, model_zoo_url, degirum_tools.get_token())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the text detection and recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text detection AI model and text recognition AI model\n",
    "text_det_model = text_det_zoo.load_model(text_det_model_name, \n",
    "                                         image_backend = \"pil\", \n",
    "                                         input_image_format=\"RAW\",\n",
    "                                         overlay_show_labels = True,\n",
    "                                         custom_postprocessor = OCRTextDetPostprocessor\n",
    "                                         )\n",
    "text_rec_model = text_rec_zoo.load_model(text_rec_model_name, \n",
    "                                         custom_postprocessor = OCRTextRecPostprocessor\n",
    "                                         )\n",
    "\n",
    "rec_H, rec_W = text_rec_model.model_info.InputW[0],text_rec_model.model_info.InputC[0]\n",
    "preprocessor = OCRTextRecPreprocessor(rec_H, rec_W)\n",
    "\n",
    "text_det_res = text_det_model(image_source)\n",
    "text_rec_preprocess = preprocessor.initialize(text_det_res, text_det_model.image_backend)\n",
    "for image_crop, index in text_rec_preprocess:\n",
    "    result = text_rec_model([image_crop])\n",
    "    text_det_res.results[index][\"label\"] = result.results[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_det_res.image_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
