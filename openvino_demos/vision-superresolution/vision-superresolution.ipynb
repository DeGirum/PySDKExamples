{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Super Resolution with DeGirum PySDK\n",
    "Super Resolution is the process of enhancing the quality of an image by increasing the pixel count using deep learning. This notebook applies Single Image Super Resolution (SISR) to frames in a 360p (480Ã—360) video in 360p resolution. A model called [single-image-super-resolution-1032](https://docs.openvino.ai/2024/omz_models_model_single_image_super_resolution_1032.html), which is available in Open Model Zoo, is used in this tutorial. It is based on the research paper cited below. \n",
    "\n",
    "Y. Liu et al., [\"An Attention-Based Approach for Single Image Super Resolution,\"](https://arxiv.org/abs/1807.06779) 2018 24th International Conference on Pattern Recognition (ICPR), 2018, pp. 2777-2784, doi: 10.1109/ICPR.2018.8545760.\n",
    "\n",
    "> **NOTE**: The Single Image Super Resolution (SISR) model used in this demo is not optimized for a video. Results may vary depending on the video.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure PySDK and degirum-tools is installed\n",
    "!pip show degirum || pip install -q degirum\n",
    "!pip show degirum-tools || pip install -q degirum-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import degirum as dg\n",
    "import degirum_tools as dgtools\n",
    "\n",
    "from superres_postprocessor import SuperResolutionResults\n",
    "\n",
    "hw_location = dg.LOCAL\n",
    "zoo_url = 'https://cs.degirum.com/degirum/super_resolution'\n",
    "\n",
    "model_name = 'singleimage_superresolution_4x--480x270_float_openvino_cpu_1'\n",
    "SuperResolutionResults.resize_factor = 4\n",
    "\n",
    "video_results_path = \"temp/superres_comparison.mp4\"\n",
    "num_frames = 200  # Maximum number of frames to read from video, set to 0 for all frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from functools import cmp_to_key\n",
    "from pathlib import Path\n",
    "import urllib\n",
    "\n",
    "from degirum_tools import environment as env\n",
    "\n",
    "@contextmanager\n",
    "def open_video_stream(video_source, max_quality): \n",
    "    \"\"\"Open OpenCV video stream from camera with given identifier.\n",
    "\n",
    "    video_source - 0-based index for local cameras\n",
    "       or IP camera URL in the format \"rtsp://<user>:<password>@<ip or hostname>\",\n",
    "       or local video file path,\n",
    "       or URL to mp4 video file,\n",
    "       or YouTube video URL\n",
    "    max_quality - The maximum video quality for YouTube videos. The units are\n",
    "       in pixels for the height of the video.\n",
    "    Returns context manager yielding video stream object and closing it on exit\n",
    "    \"\"\"\n",
    "\n",
    "    if env.get_test_mode() or video_source is None:\n",
    "        video_source = env.get_var(env.var_VideoSource, 0)\n",
    "        if isinstance(video_source, str) and video_source.isnumeric():\n",
    "            video_source = int(video_source)\n",
    "\n",
    "    if isinstance(video_source, Path):\n",
    "        video_source = str(video_source)\n",
    "\n",
    "    if isinstance(video_source, str) and urllib.parse.urlparse(\n",
    "        video_source\n",
    "    ).hostname in (\n",
    "        \"www.youtube.com\",\n",
    "        \"youtube.com\",\n",
    "        \"youtu.be\",\n",
    "    ):  # if source is YouTube video\n",
    "        import pafy\n",
    "\n",
    "        video_qualities = pafy.new(video_source).videostreams\n",
    "        # Sort descending based on vertical pixel count.\n",
    "        video_qualities = sorted(video_qualities, key=cmp_to_key(lambda a, b: b.dimensions[1] - a.dimensions[1]))\n",
    "        \n",
    "        for video in video_qualities:\n",
    "            if video.dimensions[1] <= max_quality:\n",
    "                video_source = video.url\n",
    "                break\n",
    "\n",
    "    stream = cv2.VideoCapture(video_source)  # type: ignore[arg-type]\n",
    "    if not stream.isOpened():\n",
    "        raise Exception(f\"Error opening '{video_source}' video stream\")\n",
    "    else:\n",
    "        print(f\"Successfully opened video stream '{video_source}'\")\n",
    "\n",
    "    try:\n",
    "        yield stream\n",
    "    finally:\n",
    "        stream.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference on a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "video_source = \"https://www.youtube.com/watch?v=V8yS3WIkOrA\"\n",
    "\n",
    "# Change backend back to opencv for compatibility with dgstreams\n",
    "zoo = dg.connect(hw_location, zoo_url, dgtools.get_token())\n",
    "model = zoo.load_model(model_name, image_backend='opencv', input_image_format=\"RAW\")\n",
    "\n",
    "model.custom_postprocessor = SuperResolutionResults\n",
    "\n",
    "with open_video_stream(video_source, max_quality=360) as video_stream:\n",
    "    w, h, fps = dgtools.get_video_stream_properties(video_stream)\n",
    "\n",
    "    if num_frames == 0:\n",
    "        total_frames = video_stream.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    else:\n",
    "        total_frames = num_frames\n",
    "\n",
    "    with dgtools.open_video_writer(video_results_path, w * 2, h, fps) as writer:\n",
    "        progress = dgtools.Progress(total_frames)\n",
    "\n",
    "        for i, frame in enumerate(dgtools.video_source(video_stream)):\n",
    "            if i == total_frames:\n",
    "                break\n",
    "            \n",
    "            inference_result = model([frame, frame])\n",
    "\n",
    "            # Stack super resolution result on the left and bicubic result on the right.\n",
    "            h, w, c = inference_result.image_overlay.shape\n",
    "\n",
    "            compound_image = np.zeros((h, w * 2, c), dtype=np.uint8)\n",
    "            compound_image[:h,:w] = inference_result.image_overlay\n",
    "            compound_image[:h, w:] = cv2.resize(inference_result.image, (w, h), cv2.INTER_CUBIC)\n",
    "            writer.write(compound_image)\n",
    "            progress.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgtools.ipython_display(video_results_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depthanyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
