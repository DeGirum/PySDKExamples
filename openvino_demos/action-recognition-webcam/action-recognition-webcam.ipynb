{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hw_location: where you want to run inference\n",
    "#     \"@cloud\" to use DeGirum cloud\n",
    "#     \"@local\" to run on local machine\n",
    "#     IP address for AI server inference\n",
    "# model_zoo_url: url/path for model zoo\n",
    "#     cloud_zoo_url: valid for @cloud, @local, and ai server inference options\n",
    "#     '': ai server serving models from local folder\n",
    "#     path to json file: single model zoo in case of @local inference\n",
    "# model_name: name of the model for running AI inference\n",
    "# image_source: image source for inference\n",
    "#     path to image file\n",
    "#     URL of image\n",
    "#     PIL image object\n",
    "#     numpy array\n",
    "\n",
    "hw_location = \"@local\"\n",
    "model_zoo_url = \"https://cs.degirum.com/degirum/timm_gender_model_test\"\n",
    "encoder_model_name = \"encoder_action_recognition--224x224_float_openvino_cpu_1\"\n",
    "decoder_model_name = \"decoder_action_recognition--224x224_float_openvino_cpu_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg\n",
    "import degirum_tools\n",
    "\n",
    "action_rec_zoo = dg.connect(hw_location, model_zoo_url, degirum_tools.get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessor_action_rec_encoder import ActionRecEncoderPreprocessor\n",
    "from postprocessor_action_rec_decoder import ActionRecDecoderPostprocessor\n",
    "encoder_model = action_rec_zoo.load_model(encoder_model_name)\n",
    "decoder_model = action_rec_zoo.load_model(decoder_model_name, custom_postprocessor = ActionRecDecoderPostprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_w, dec_h = decoder_model.model_info.InputW[0],decoder_model.model_info.InputC[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_source = \"https://archive.org/serve/ISSVideoResourceLifeOnStation720p/ISS%20Video%20Resource_LifeOnStation_720p.mp4\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "def image_overlay(frame, result_de):\n",
    "    for idx, item in enumerate(result_de):\n",
    "        label_text = item['label']\n",
    "        text_position = (10, 30 + idx * 30)  # Adjust vertical position for each label\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 0.8\n",
    "        font_color = (255, 255, 255)  # White color in BGR\n",
    "        thickness = 2\n",
    "        cv2.putText(frame, label_text, text_position, font, font_scale, font_color, thickness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_results_path = \"action_rec_output.mp4\"\n",
    "num_frames = 100  # Maximum number of frames to read from video, set to 0 for all frames.\n",
    "sample_duration = 16\n",
    "skip_first_frames = 600\n",
    "size = encoder_model.model_info.InputC[0]\n",
    "with degirum_tools.open_video_stream(video_source) as video_stream:\n",
    "    w, h, fps = degirum_tools.get_video_stream_properties(video_stream)\n",
    "    fps = 30\n",
    "    if num_frames == 0:\n",
    "        total_frames = video_stream.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    else:\n",
    "        total_frames = num_frames\n",
    "    encoder_output = []\n",
    "    counter = 0\n",
    "    frames = []\n",
    "    with degirum_tools.open_video_writer(video_results_path, w, h, fps) as writer:\n",
    "        progress = degirum_tools.Progress(total_frames)\n",
    "        \n",
    "        for i, frame in enumerate(degirum_tools.video_source(video_stream)):\n",
    "            if i < skip_first_frames:\n",
    "                continue\n",
    "            if i == skip_first_frames+total_frames:\n",
    "                break\n",
    "            counter = counter + 1\n",
    "            \n",
    "            scale = 1280 / max(frame.shape)\n",
    "            # Adaptative resize for visualization.\n",
    "            if scale < 1:\n",
    "                frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            if counter % 2 == 0:\n",
    "                preprocessed = ActionRecEncoderPreprocessor(size).preprocess_frame_for_encoder(frame)\n",
    "                encoder_output.append(encoder_model(preprocessed).results[0][\"data\"])\n",
    "\n",
    "                if len(encoder_output) == sample_duration:\n",
    "                    decoder_input = np.concatenate(encoder_output, axis=0)\n",
    "                    # Organize input shape vector to the Decoder (shape: [1x16x512]]\n",
    "                    decoder_input = decoder_input.transpose((2, 3, 0, 1))\n",
    "                    decoder_input = decoder_input.reshape((1, dec_w, dec_h))\n",
    "                    decoder_input = decoder_input.astype(np.float32)\n",
    "                    result_de = decoder_model(decoder_input) \n",
    "                    for frame in frames:\n",
    "                        image_overlay(frame, result_de.results)\n",
    "                        writer.write(frame)\n",
    "                    encoder_output = []\n",
    "                    frames = []\n",
    "            frames.append(frame)                   \n",
    "            progress.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
