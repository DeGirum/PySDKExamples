{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background removal with RMBG v1.4 and OpenVINO running in DeGirum PySDK\n",
    "\n",
    "Background matting is the process of accurately estimating the foreground object in images and videos. It is a very important technique in image and video editing applications, particularly in film production for creating visual effects. In case of image segmentation, we segment the image into foreground and background by labeling the pixels. Image segmentation generates a binary image, in which a pixel either belongs to foreground or background. However, Image Matting is different from the image segmentation, wherein some pixels may belong to foreground as well as background, such pixels are called partial or mixed pixels. In order to fully separate the foreground from the background in an image, accurate estimation of the alpha values for partial or mixed pixels is necessary.\n",
    "\n",
    "\n",
    "### RMBG v1.4\n",
    "\n",
    "RMBG v1.4 is a background removal model, designed to effectively separate foreground from background in a range of categories and image types. This model has been trained on a carefully selected dataset, which includes: general stock images, e-commerce, gaming, and advertising content, making it suitable for commercial use cases powering enterprise content creation at scale. The accuracy, efficiency, and versatility currently rival leading source-available models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import degirum as dg\n",
    "import degirum_tools as dgtools\n",
    "\n",
    "model_name = 'rmbg_background_removal--1024x1024_float_openvino_cpu_1'\n",
    "zoo_url = 'https://cs.degirum.com/degirum/openvino_demos'\n",
    "img_path = 'example_input.jpg'\n",
    "\n",
    "zoo = dg.connect(dg.CLOUD, zoo_url, dgtools.get_token())\n",
    "model = zoo.load_model(model_name)\n",
    "img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "h_in, w_in, c_in = img_rgb.shape\n",
    "\n",
    "# Inference\n",
    "input = cv2.resize(img_rgb, (1024,1024)).astype(np.float32) / 255\n",
    "input = input.transpose((2, 0, 1))[np.newaxis, ...]\n",
    "res = model(input)\n",
    "res = res.results[0]['data']\n",
    "\n",
    "# Post-process\n",
    "mask = cv2.resize(np.squeeze(res), (w_in, h_in))[..., np.newaxis]\n",
    "masked_image = (img_rgb * mask).astype(np.uint8)\n",
    "\n",
    "# Show results\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "plt.title(\"Input\", fontsize=20)\n",
    "ax1.axis(\"off\")\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "plt.title(\"Masked\", fontsize=20)\n",
    "ax2.axis(\"off\")\n",
    "ax1.imshow(img_rgb)\n",
    "ax2.imshow(masked_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnxruntime-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
