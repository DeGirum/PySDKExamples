{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Started with DeGirum PySDK in Google Colab! \n",
    "Welcome to the DeGirum PySDK Quickstart Colab! This notebook is designed to help you get started with PySDK right away, without the need to set up tools or dependencies on your local machine. While the Colab environment may not provide the full range of PySDK’s functionality, the included examples will give you a solid understanding of its capabilities. If you’d like to explore the complete features and unlock the full potential of PySDK, we encourage you to install it on your own machine. Let’s get started by installing the `degirum` and `degirum_tools` packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install degirum\n",
    "%pip install degirum_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the token\n",
    "Since we’ll be using hardware hosted in the cloud by DeGirum, you’ll need to set a token to access these resources. This token serves as your secure key to connect to DeGirum’s cloud infrastructure and enables you to run the examples provided in this notebook seamlessly.\n",
    "\n",
    "To guide you through the process of obtaining your token, refer to the video below:  \n",
    "\n",
    "[![How to Obtain and Set Your Token](https://img.youtube.com/vi/PLACEHOLDER/0.jpg)](https://www.youtube.com/watch?v=PLACEHOLDER)  \n",
    "\n",
    "*Click on the thumbnail to watch the tutorial video.*  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "degirum_cloud_token = '<paste your degirum cloud token here>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Your First Inference\n",
    "\n",
    "In this section, we’ll demonstrate how to use the DeGirum PySDK to perform object detection on an example image using a cloud-hosted AI model. Here’s what the code does:\n",
    "\n",
    "1. **Import Required Libraries**: The `degirum` package is used for loading and using AI models, and `degirum_tools` provides utility functions such as obtaining a token and displaying results.\n",
    "\n",
    "2. **Load the Object Detection Model**: The `degirum.load_model()` method loads a pre-trained YOLOv8 object detection model hosted in the DeGirum cloud. The key parameters here are:\n",
    "   - `model_name`: Specifies the AI model to use.\n",
    "   - `inference_host_address`: Indicates where inference will be performed. Setting it to `\"@cloud\"` connects the request to DeGirum’s cloud-hosted hardware, leveraging powerful compute resources without requiring local setup. For on-premise or local deployments, this value can be replaced with the IP address or hostname of the target device.\n",
    "   - `zoo_url`: Defines the location of the model zoo, a repository of pre-trained AI models. In this example, it is set to `'degirum/models_hailort'`, specifying a cloud-hosted model zoo managed by DeGirum. The `zoo_url` format typically follows `<organization>/<model_zoo_name>` and can be customized for private repositories.\n",
    "   - `token`: Authenticates your access to the cloud-hosted resources, retrieved here using `degirum_tools.get_token()`.\n",
    "\n",
    "3. **Run Inference on an Image**: The model processes an example image (a URL pointing to an example image) and generates detection results.\n",
    "\n",
    "4. **Display the Results**: The numeric results of the inference, including detected bounding boxes and class IDs, are printed to the console. Additionally, using `degirum_tools.Display`, the inference results are visualized with object overlays on the input image.\n",
    "\n",
    "This code provides a simple yet powerful introduction to the DeGirum PySDK, demonstrating how to load a cloud-hosted model, run inference, and interpret the results in just a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg, degirum_tools\n",
    "\n",
    "# load object detection AI model\n",
    "model = dg.load_model(\n",
    "    model_name=\"yolov8n_relu6_coco--640x640_quant_hailort_hailo8_1\",\n",
    "    inference_host_address=\"@cloud\",\n",
    "    zoo_url='degirum/models_hailort',\n",
    "    token=degirum_cloud_token,\n",
    ")\n",
    "\n",
    "# perform AI model inference on given image source\n",
    "inference_result = model(\"https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/bikes.jpg\")\n",
    "\n",
    "# show results of inference\n",
    "print(inference_result)  # numeric results\n",
    "with degirum_tools.Display(\"AI Camera: Press q or x to Quit\") as display:\n",
    "    display.show_image(inference_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unified AI Inference with DeGirum PySDK\n",
    "We now highlight the core capabilities of the DeGirum PySDK, showcasing its flexibility and simplicity in deploying AI models across multiple hardware platforms. By specifying the appropriate model name and model zoo, users can seamlessly run different types of models, such as classification, detection, keypoint detection, or segmentation, using the same unified interface. The JSON configuration provided below illustrates how users can select the model name based on the desired AI task and hardware option, as well as how to choose the appropriate model zoo URL. This approach abstracts hardware-specific complexities, enabling a consistent experience for diverse AI tasks. Additionally, the `result.image_overlay` feature ensures that outputs—whether bounding boxes, keypoints, or segmentation masks—are visualized in a unified manner, simplifying result interpretation. Combined with `degirum_tools.Display`, this enables intuitive visualization of inference outputs directly overlaid on the input image. This example underscores PySDK’s design philosophy: different models, same code, unified visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import degirum as dg, degirum_tools\n",
    "\n",
    "# Define configurations\n",
    "model_configurations = {\n",
    "    \"Hailo\": {\n",
    "        \"zoo_url\": \"degirum/models_hailort\",\n",
    "        \"model_names\": {\n",
    "            \"classification\": [\"yolov8s_silu_imagenet--224x224_quant_hailort_hailo8_1\"],\n",
    "            \"detection\": [\"yolov8n_relu6_coco--640x640_quant_hailort_hailo8_1\"],\n",
    "            \"keypoint_detection\": [\"yolov8n_relu6_widerface_kpts--640x640_quant_hailort_hailo8_1\"],\n",
    "            \"segmentation\": [\"yolov8n_relu6_coco_seg--640x640_quant_hailort_hailo8_1\"],\n",
    "        },\n",
    "    },\n",
    "    \"Intel\": {\n",
    "        \"zoo_url\": \"degirum/models_openvino\",\n",
    "        \"model_names\": {\n",
    "            \"classification\": [\"yolov8s_silu_imagenet--224x224_float_openvino_multidevice_1\"],\n",
    "            \"detection\": [\"yolov8n_relu6_coco--640x640_float_openvino_multidevice_1\"],\n",
    "            \"keypoint_detection\": [\"yolov8n_relu6_widerface_kpts--640x640_float_openvino_multidevice_1\"],\n",
    "            \"segmentation\": [\"yolov8n_relu6_coco_seg--640x640_float_openvino_multidevice_1\"],\n",
    "        },\n",
    "    },\n",
    "    \"DeGirum\": {\n",
    "        \"zoo_url\": \"degirum/models_n2x\",\n",
    "        \"model_names\": {\n",
    "            \"classification\": [\"yolov8s_silu_imagenet--224x224_quant_n2x_orca1_1\"],\n",
    "            \"detection\": [\"yolov8n_relu6_coco--640x640_quant_n2x_orca1_1\"],\n",
    "            \"keypoint_detection\": [\"yolov8n_relu6_widerface_kpts--640x640_quant_n2x_orca1_1\"],\n",
    "            \"segmentation\": [\"yolov8n_relu6_coco_seg--640x640_quant_n2x_orca1_1\"],\n",
    "        },\n",
    "    },\n",
    "    \"RockChip\": {\n",
    "        \"zoo_url\": \"degirum/models_rknn\",\n",
    "        \"model_names\": {\n",
    "            \"classification\": [\"yolov8s_silu_imagenet--224x224_quant_rknn_rk3588_1\"],\n",
    "            \"detection\": [\"yolov8n_relu6_coco--640x640_quant_rknn_rk3588_1\"],\n",
    "            \"keypoint_detection\": [\"yolov8n_relu6_widerface_kpts--640x640_quant_rknn_rk3588_1\"],\n",
    "            \"segmentation\": [\"yolov8n_relu6_coco_seg--640x640_quant_rknn_rk3588_1\"],\n",
    "        },\n",
    "    },\n",
    "    \"Google\": {\n",
    "        \"zoo_url\": \"degirum/models_tflite\",\n",
    "        \"model_names\": {\n",
    "            \"classification\": [\"yolov8s_silu_imagenet--224x224_quant_tflite_edgetpu_1\"],\n",
    "            \"detection\": [\"yolov8n_relu6_coco--640x640_quant_tflite_edgetpu_1\"],\n",
    "            \"keypoint_detection\": [\"yolov8n_relu6_widerface_kpts--640x640_quant_tflite_edgetpu_1\"],\n",
    "            \"segmentation\": [\"yolov8n_relu6_coco_seg--640x640_quant_tflite_edgetpu_1\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "source_images = {\n",
    "    \"classification\": \"https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/Cat.jpg\",\n",
    "    \"detection\": \"https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/bikes.jpg\",\n",
    "    \"keypoint_detection\": \"https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/Mask1.jpg\",\n",
    "    \"segmentation\": \"https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/ThreePersons.jpg\",\n",
    "}\n",
    "\n",
    "# Create widgets\n",
    "hardware_dropdown = widgets.Dropdown(\n",
    "    options=model_configurations.keys(),\n",
    "    value=\"Intel\",\n",
    "    description=\"Hardware:\",\n",
    ")\n",
    "\n",
    "model_type_dropdown = widgets.Dropdown(\n",
    "    options=list(source_images.keys()),\n",
    "    value=\"detection\",\n",
    "    description=\"Model Type:\",\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(\n",
    "    description=\"Run Inference\",\n",
    "    button_style=\"success\",  # Optional: 'success', 'info', 'warning', 'danger'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define the inference function\n",
    "def run_inference(button_click):\n",
    "    with output:\n",
    "        output.clear_output()  # Clear previous output\n",
    "        hardware_option = hardware_dropdown.value\n",
    "        model_type = model_type_dropdown.value\n",
    "\n",
    "        inference_host_address = \"@cloud\"\n",
    "        zoo_url = model_configurations[hardware_option][\"zoo_url\"]\n",
    "        model_name = model_configurations[hardware_option][\"model_names\"][model_type][0]\n",
    "        source_image = source_images[model_type]\n",
    "\n",
    "        print(f\"Running inference on hardware: {hardware_option}\")\n",
    "        print(f\"Model type: {model_type}\")\n",
    "        print(f\"Model name: {model_name}\")\n",
    "\n",
    "        # Load and run inference\n",
    "        model = dg.load_model(\n",
    "            model_name=model_name,\n",
    "            inference_host_address=inference_host_address,\n",
    "            zoo_url=zoo_url,\n",
    "            token=degirum_cloud_token,\n",
    "        )\n",
    "        inference_result = model(source_image)\n",
    "\n",
    "        print(\"Inference result:\")\n",
    "        print(inference_result)\n",
    "        with degirum_tools.Display(\"AI Camera: Press x or q to quit\") as display:\n",
    "            display.show_image(inference_result)\n",
    "\n",
    "# Link the Run button to the inference function\n",
    "run_button.on_click(run_inference)\n",
    "\n",
    "# Display widgets and output\n",
    "display(hardware_dropdown, model_type_dropdown, run_button, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore and Experiment with DeGirum PySDK\n",
    "\n",
    "This example demonstrates how to perform AI inference using DeGirum PySDK with a pre-trained model hosted in the cloud. We encourage you to experiment further by trying out different **model zoos**, **model names**, and **image sources**. For instance, you can explore various AI tasks such as object detection, classification, keypoint detection, or segmentation by selecting models from different model zoos (e.g., `models_hailort`, `models_openvino`, `models_n2x`, etc.) and providing images of your choice. This flexibility showcases PySDK's unified API, allowing you to customize and test AI inference across multiple hardware platforms and tasks effortlessly. Dive in and discover the possibilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg, degirum_tools\n",
    "\n",
    "hw_location = \"@cloud\" # \"@cloud\" for cloud inference, \"@local\" for local inference, or IP address for AI server inference\n",
    "model_zoo_url = \"degirum/models_hailort\" # models_hailort, models_openvino, models_n2x, models_rknn, models_tflite\n",
    "model_name = \"yolov8n_relu6_coco--640x640_quant_hailort_hailo8_1\"\n",
    "image_source = \"https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/Mask1.jpg\"\n",
    "\n",
    "# load object detection AI model\n",
    "model = dg.load_model(\n",
    "    model_name=model_name,\n",
    "    inference_host_address=hw_location,\n",
    "    zoo_url=model_zoo_url,\n",
    "    token=degirum_cloud_token\n",
    ")\n",
    "\n",
    "# perform AI model inference on given image source\n",
    "inference_result = model(image_source)\n",
    "\n",
    "# show results of inference\n",
    "print(inference_result)  # numeric results\n",
    "with degirum_tools.Display(\"AI Camera\") as display:\n",
    "    display.show_image(inference_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
