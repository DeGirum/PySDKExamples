{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f257328f",
   "metadata": {},
   "source": [
    "## Example script illustrating sound classification on audio stream\n",
    "This notebook is an example of how to use DeGirum PySDK to do sound classification AI inference of an audio stream.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you need to specify the appropriate `hw_location` option.\n",
    "\n",
    "You also need to specify your cloud API access token in [env.ini](../../env.ini) file, located in the same repository as this notebook.\n",
    "\n",
    "**pyaudio package with portaudio is required to run this sample**\n",
    "\n",
    "The script uses a WAV file for inference. Alternatively, you may use local microphone connected to the machine, by changing the `audio_source`.\n",
    "The mic index or WAV filename needs to be specified either in the code below by assigning `audio_source`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2080ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure degirum-tools package is installed\n",
    "!pip show degirum-tools || pip install degirum-tools\n",
    "\n",
    "# to install pyaudio package, uncomment the following lines\n",
    "#!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0\n",
    "#!pip show pyaudio || pip install pyaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7227c649-6c23-41d1-a6df-4247f4a6a480",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Specify where do you want to run your inferences, model_zoo_url, model_name, and audio_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef133f4-8197-4de5-a44e-c76dbbd39a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hw_location: where you want to run inference\n",
    "#     \"@cloud\" to use DeGirum cloud\n",
    "#     \"@local\" to run on local machine\n",
    "#     IP address for AI server inference\n",
    "# model_zoo_url: url/path for model zoo\n",
    "#     cloud_zoo_url: valid for @cloud, @local, and ai server inference options\n",
    "#     '': ai server serving models from local folder\n",
    "#     path to json file: single model zoo in case of @local inference\n",
    "# model_name: name of the model for running AI inference\n",
    "# audio_source: audio source for inference\n",
    "#     microphone index for local microphone\n",
    "#     path to audio file (mp4/wav etc)\n",
    "hw_location = \"@cloud\"\n",
    "model_zoo_url = \"https://cs.degirum.com/degirum/public\"\n",
    "model_name = \"mobilenet_v1_yamnet_sound_cls--96x64_quant_n2x_orca1_1\"\n",
    "audio_source = \"../../images/example_audio.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86162da-d4bc-42d6-b839-b10025306796",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a1753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import degirum as dg, degirum_tools\n",
    "\n",
    "# configure for Google Colab\n",
    "degirum_tools.configure_colab()\n",
    "# connect to AI inference engine getting token from env.ini file\n",
    "zoo = dg.connect(hw_location, model_zoo_url, degirum_tools.get_token())\n",
    "# load sound classification model\n",
    "model = zoo.load_model(model_name)\n",
    "\n",
    "abort = False  # stream abort flag\n",
    "N = 5  # inference results history depth\n",
    "history = []  # list of N consecutive inference results\n",
    "\n",
    "sampling_rate_hz = model.model_info.InputSamplingRate[0]\n",
    "read_buf_size = model.model_info.InputWaveformSize[0] // 2  # to have 50% overlap\n",
    "\n",
    "# Acquire model input stream object\n",
    "with degirum_tools.open_audio_stream(\n",
    "    sampling_rate_hz, read_buf_size, audio_source\n",
    ") as stream:\n",
    "    #\n",
    "    # AI prediction loop.\n",
    "    # emit keyboard typing sound to stop\n",
    "    #\n",
    "    for res in model.predict_batch(\n",
    "        degirum_tools.audio_overlapped_source(stream, lambda: abort)\n",
    "    ):\n",
    "        # add top inference result to history\n",
    "        history.insert(0, f\"{res.results[0]['label']}: {res.results[0]['score']}\")\n",
    "        if len(history) > N:  # keep only N last elements in history\n",
    "            history.pop()\n",
    "\n",
    "        clear_output(wait=True)  # clear Jupyter output cell\n",
    "        for m in history:  # print history\n",
    "            print(m)\n",
    "\n",
    "        if res.results[0][\"label\"] == \"Typing\":  # check for stop condition\n",
    "            abort = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39e615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
