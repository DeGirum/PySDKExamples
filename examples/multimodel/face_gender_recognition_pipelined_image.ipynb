{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08e7226",
   "metadata": {},
   "source": [
    "## This notebook is an example of how to pipeline two models. \n",
    "This notebook is an example of how to use DeGirum PySDK to do AI inference of a graphical file using \n",
    "two AI models: license plate detection and license recognition. The license plate detection model \n",
    "is run on the image and the results are then processed by the license recognition model, \n",
    "one license plate at a time. Combined result is then displayed.\n",
    "This script uses PIL as image processing backend.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you just need to uncomment **one** of the lines in the code below.\n",
    "\n",
    "You also need to specify your cloud API access token, cloud zoo URLs, and AI server hostname in [env.ini](../../env.ini) file, located in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure degirum-tools package is installed\n",
    "!pip show degirum-tools || pip install degirum-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960afca-3c84-4794-a8d0-ae894260f40b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Specify where do you want to run your inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01889e8e-c81a-4514-a16e-bb13652e61e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hw_location: Where you want to run inference.\n",
    "#     Use \"@cloud\" to use DeGirum cloud.\n",
    "#     Use \"@local\" to run on local machine.\n",
    "#     Use an IP address for AI server inference.\n",
    "hw_location = \"@cloud\"\n",
    "\n",
    "# face_model_zoo_url: URL/path for the face model zoo.\n",
    "#     Use cloud_zoo_url for @cloud, @local, and AI server inference options.\n",
    "#     Use '' for an AI server serving models from a local folder.\n",
    "#     Use a path to a JSON file for a single model zoo in case of @local inference.\n",
    "face_model_zoo_url = \"https://cs.degirum.com/degirum/ultralytics_v6\"\n",
    "\n",
    "# face_model_name: Name of the model for face detection.\n",
    "face_model_name = \"yolov8n_relu6_face--640x640_quant_n2x_orca1_1\"\n",
    "\n",
    "# gender_model_zoo_url: URL/path for the gender model zoo.\n",
    "gender_model_zoo_url = \"https://cs.degirum.com/degirum/openvino\"\n",
    "\n",
    "# gender_model_name: Name of the model for gender detection.\n",
    "gender_model_name = \"mobilenet_v2_gender--160x160_float_openvino_cpu_1\"\n",
    "\n",
    "# video_source: Video source for inference.\n",
    "#     Use a camera index for a local webcam.\n",
    "#     Use a URL of an RTSP stream.\n",
    "#     Use a URL of a YouTube video.\n",
    "#     Use a path to a video file (like an MP4).\n",
    "video_source='../../images/faces_and_gender.mp4'                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d2ce9-610e-4727-a18d-f0467b326d7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "878db7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully opened video stream '../../images/faces_and_gender.mp4'\n"
     ]
    }
   ],
   "source": [
    "import degirum as dg\n",
    "import degirum_tools\n",
    "\n",
    "# Configure for Google Colab\n",
    "degirum_tools.configure_colab()\n",
    "\n",
    "# Connect to AI inference engine getting token from env.ini file\n",
    "face_zoo = dg.connect(hw_location, face_model_zoo_url, degirum_tools.get_token())\n",
    "gender_zoo = dg.connect(hw_location, gender_model_zoo_url, degirum_tools.get_token())\n",
    "\n",
    "# Load models\n",
    "with face_zoo.load_model(face_model_name) as face_model:\n",
    "    with gender_zoo.load_model(gender_model_name) as gender_model:\n",
    "        # Create a compound cropping model with 50% crop extent\n",
    "        crop_model = degirum_tools.CroppingAndClassifyingCompoundModel(\n",
    "            face_model, gender_model, 50.0\n",
    "        )\n",
    "\n",
    "        # Detect faces and genders\n",
    "        with degirum_tools.Display(\"Faces and Gender\") as display:\n",
    "            for gender_results in degirum_tools.predict_stream(crop_model, video_source):\n",
    "                display.show(gender_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29966e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (supervision)",
   "language": "python",
   "name": "supervision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "f77ba0ef977241afac66801d7297b5fb2ffa6cc21668a24d017a9f23b5f689e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
