{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c66bb0b",
   "metadata": {},
   "source": [
    "## Examples of degirum_tools.streams module usage\n",
    "This notebook contains various examples, which demonstrate the capabilities of degirum_tools.streams module: streaming toolkit for PySDK.\n",
    "\n",
    "The script also uses a video file to run this code. The video file path needs to be specified by defining video_source variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d6ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure degirum-tools package is installed\n",
    "!pip show degirum-tools || pip install degirum-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_source: video source for inference\n",
    "#     camera index for local camera\n",
    "#     URL of RTSP stream\n",
    "#     URL of YouTube Video\n",
    "#     path to video file (mp4 etc)\n",
    "video_source = (\n",
    "    \"https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/example_video.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1077ac0e",
   "metadata": {},
   "source": [
    "### Simplest example: video source is connected to video display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2008ada1-9b55-4739-aa0c-0e48370625db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from degirum_tools.streams import *\n",
    "\n",
    "# create Composition: an object, which keeps all streaming blocks (called gizmos) and runs them in parallel\n",
    "c = Composition()\n",
    "\n",
    "# create gizmos:\n",
    "source = VideoSourceGizmo(video_source)  # video source gizmo\n",
    "display = VideoDisplayGizmo(\n",
    "    \"press `x` or `q` to stop\", allow_drop=False\n",
    ")  # video display gizmo\n",
    "\n",
    "# Create pipeline: connect display input to source output\n",
    "display.connect_to(source)\n",
    "\n",
    "# add gizmos to composition\n",
    "c.add(source)\n",
    "c.add(display)\n",
    "\n",
    "# start composition\n",
    "c.start()\n",
    "\n",
    "# call c.stop() to stop composition or just press `x` or `q` in display window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c57054",
   "metadata": {},
   "source": [
    "### Same example, but with compact syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83524ee-f48d-469a-addf-0642f23b1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from degirum_tools.streams import *\n",
    "\n",
    "c = Composition()\n",
    "\n",
    "# Create gizmos and pipeline as a single-liner:\n",
    "# we use __call__() operator of Composition class instead of add() method\n",
    "# and we use `>>` operator of gizmo classes instead of connect_to() method\n",
    "c(VideoSourceGizmo(video_source)) >> c(VideoDisplayGizmo())\n",
    "\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00314218",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of forked streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f71adfe-b317-4bd3-ad08-564d10af6f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from degirum_tools.streams import *\n",
    "\n",
    "c = Composition()\n",
    "\n",
    "# create and add to composition all required gizmos\n",
    "source = c.add(VideoSourceGizmo(video_source))  # video source gizmo\n",
    "display = c.add(\n",
    "    VideoDisplayGizmo([\"Original\", \"Resized\"])\n",
    ")  # two-input display gizmo: will show two windows\n",
    "resizer = c.add(ResizingGizmo(300, 200))  # resizing gizmo\n",
    "\n",
    "# Create pipeline: the image source is fed to a display and to the image resizing gizmo,\n",
    "# which is then fed to another display.\n",
    "\n",
    "display.connect_to(source, 0)  # display input 0 is \"Original\"\n",
    "resizer.connect_to(source)\n",
    "display.connect_to(resizer, 1)  # display input 1 is \"Resized\"\n",
    "\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe7b1d0-5cd7-4020-84b4-a2cd0dfec911",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of capturing video input into file with simultaneous display on a screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a77196-f465-495b-b511-65a10ae15b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from degirum_tools.streams import *\n",
    "\n",
    "c = Composition()\n",
    "\n",
    "source = c.add(VideoSourceGizmo(video_source))\n",
    "display = c.add(VideoDisplayGizmo())\n",
    "saver = c.add(VideoSaverGizmo(\"temp/mycapture.mp4\"))\n",
    "\n",
    "source >> display\n",
    "source >> saver\n",
    "\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe09275e-8fb5-47b8-911f-6cd625680556",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of AI inference from the camera with AI inference results display\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you need to specify the appropriate `hw_location` option. \n",
    "\n",
    "When running this notebook locally, you need to specify your cloud API access token in the [env.ini](../../env.ini) file, located in the same directory as this notebook.\n",
    "\n",
    "When running this notebook in Google Colab, the cloud API access token should be stored in a user secret named `DEGIRUM_CLOUD_TOKEN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hw_location: where you want to run inference\n",
    "#     \"@cloud\" to use DeGirum cloud\n",
    "#     \"@local\" to run on local machine\n",
    "#     IP address for AI server inference\n",
    "# model_zoo_url: url/path for model zoo\n",
    "#     cloud_zoo_url: valid for @cloud, @local, and ai server inference options\n",
    "#     '': ai server serving models from local folder\n",
    "#     path to json file: single model zoo in case of @local inference\n",
    "# model_name: name of the model for running AI inference\n",
    "hw_location = \"@cloud\"\n",
    "model_zoo_url = \"https://cs.degirum.com/degirum/public\"\n",
    "model_name = \"yolo_v5s_coco--512x512_quant_n2x_orca1_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236df882-756f-481e-bb28-f4290286b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg, degirum_tools\n",
    "from degirum_tools.streams import *\n",
    "\n",
    "# connect to AI inference engine\n",
    "zoo = dg.connect(hw_location, model_zoo_url, degirum_tools.get_token())\n",
    "\n",
    "# load some object detection AI model\n",
    "model = zoo.load_model(model_name)\n",
    "\n",
    "c = Composition()\n",
    "\n",
    "# create gizmos\n",
    "source = c.add(VideoSourceGizmo(video_source))  # video source\n",
    "detection = c.add(AiSimpleGizmo(model))  # AI model\n",
    "display = c.add(\n",
    "    VideoDisplayGizmo(\"Detection\", show_ai_overlay=True, show_fps=True)\n",
    ")  # display\n",
    "\n",
    "# create pipeline\n",
    "source >> detection >> display\n",
    "\n",
    "c.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3eadf612-390e-4cd4-9dc3-94fd77b3869c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of AI inference with separate pre-processing stage\n",
    "\n",
    "Frames from the camera are supplied to the object detection model preprocessor and then to the object detection model\n",
    "itself. This improves performance by allowing the image resizing preprocessor to run in a separate thread.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you need to specify the appropriate `hw_location` option. \n",
    "\n",
    "When running this notebook locally, you need to specify your cloud API access token in the [env.ini](../../env.ini) file, located in the same directory as this notebook.\n",
    "\n",
    "When running this notebook in Google Colab, the cloud API access token should be stored in a user secret named `DEGIRUM_CLOUD_TOKEN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hw_location: where you want to run inference\n",
    "#     \"@cloud\" to use DeGirum cloud\n",
    "#     \"@local\" to run on local machine\n",
    "#     IP address for AI server inference\n",
    "# model_zoo_url: url/path for model zoo\n",
    "#     cloud_zoo_url: valid for @cloud, @local, and ai server inference options\n",
    "#     '': ai server serving models from local folder\n",
    "#     path to json file: single model zoo in case of @local inference\n",
    "# model_name: name of the model for running AI inference\n",
    "hw_location = \"@cloud\"\n",
    "model_zoo_url = \"https://cs.degirum.com/degirum/public\"\n",
    "model_name = \"yolo_v5s_coco--512x512_quant_n2x_orca1_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8608dd98-f64e-4a8e-b862-0f378f877cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg, degirum_tools\n",
    "from degirum_tools.streams import *\n",
    "\n",
    "# connect to AI inference engine\n",
    "zoo = dg.connect(hw_location, model_zoo_url, degirum_tools.get_token())\n",
    "\n",
    "# load AI model\n",
    "model = zoo.load_model(model_name)\n",
    "\n",
    "c = Composition()\n",
    "\n",
    "# create gizmos\n",
    "source = c.add(VideoSourceGizmo(video_source))  # video source\n",
    "preprocessor = c.add(AiPreprocessGizmo(model))\n",
    "detection = c.add(AiSimpleGizmo(model))\n",
    "display = c.add(\n",
    "    VideoDisplayGizmo(\"Objects\", show_ai_overlay=True, show_fps=True)\n",
    ")  # display\n",
    "\n",
    "# create pipeline\n",
    "source >> preprocessor >> detection >> display\n",
    "\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566183e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
