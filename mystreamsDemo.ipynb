{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62a2ee2",
   "metadata": {},
   "source": [
    "## Examples of `mystreams` module usage \n",
    "\n",
    "This notebook contains various examples, which demonstrate the capabilities of `mystreams` module: streaming toolkit for PySDK.\n",
    "\n",
    "The script also uses either a web camera or local camera connected to the machine running this code. The camera index or URL needs to be specified either in the code below by assigning `camera_id` or in .env file by defining `CAMERA_ID` variable and assigning `camera_id = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ca2536-744d-43f1-b30c-3321968f3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_id = 0         # camera index or URL; 0 to use default local camera, None to take from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1077ac0e",
   "metadata": {},
   "source": [
    "### Simplest example: video source is connected to video display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2008ada1-9b55-4739-aa0c-0e48370625db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mystreams import *\n",
    "\n",
    "# create Composition: an object, which keeps all streaming blocks (called gizmos) and runs them in parallel\n",
    "c = Composition();\n",
    "\n",
    "# create gizmos:\n",
    "source = VideoSourceGizmo(camera_id) # video source gizmo\n",
    "display = VideoDisplayGizmo(\"press `x` or `q` to stop\") # video display gizmo\n",
    "\n",
    "# Create pipeline: connect display input to source output\n",
    "display.connect_to(source)\n",
    "\n",
    "# add gizmos to composition\n",
    "c.add(source)\n",
    "c.add(display)\n",
    "\n",
    "# start composition\n",
    "c.start()\n",
    "\n",
    "# call c.stop() to stop composition or just press `x` or `q` in display window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c57054",
   "metadata": {},
   "source": [
    "### Same example, but with compact syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83524ee-f48d-469a-addf-0642f23b1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mystreams import *\n",
    "\n",
    "c = Composition();\n",
    "\n",
    "# Create gizmos and pipeline as a single-liner:\n",
    "# we use __call__() operator of Composition class instead of add() method\n",
    "# and we use `>>` operator of gizmo classes instead of connect_to() method\n",
    "c(VideoSourceGizmo(camera_id)) >> c(VideoDisplayGizmo())\n",
    "\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00314218",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of forked streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f71adfe-b317-4bd3-ad08-564d10af6f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mystreams import *\n",
    "\n",
    "c = Composition();\n",
    "\n",
    "# create and add to composition all required gizmos\n",
    "source = c.add(VideoSourceGizmo(camera_id))\n",
    "original_display = c.add(VideoDisplayGizmo(\"Original\"))\n",
    "resized_display = c.add(VideoDisplayGizmo(\"Resized\"))\n",
    "resizer = c.add(ResizingGizmo(300, 200))\n",
    "\n",
    "# Create pipeline: the image source is fed to a display and to the image resizing gizmo, which is then fed to another display.\n",
    "# It is equivalent to:\n",
    "#    original_display.connect_to(source)\n",
    "#    resizer.connect_to(source)\n",
    "#    resized_display.connect_to(resizer)\n",
    "\n",
    "source >> original_display\n",
    "source >> resizer >> resized_display\n",
    "\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe7b1d0-5cd7-4020-84b4-a2cd0dfec911",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of capturing video input into file with simultaneous display on a screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a77196-f465-495b-b511-65a10ae15b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mystreams import *\n",
    "\n",
    "c = Composition();\n",
    "\n",
    "source = c.add(VideoSourceGizmo(camera_id))\n",
    "display = c.add(VideoDisplayGizmo())\n",
    "saver = c.add(VideoSaverGizmo(\"mycapture.mp4\"))\n",
    "\n",
    "source >> display\n",
    "source >> saver\n",
    "\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe09275e-8fb5-47b8-911f-6cd625680556",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of AI inference from the camera with AI inference results display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063592aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg\n",
    "import mytools\n",
    "from mystreams import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5911c74c",
   "metadata": {},
   "source": [
    "### Set inference option here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please uncomment and edit one of the following inference options to specify your system configuration case according to\n",
    "# https://cs.degirum.com/doc/0.5.0/degirum.html#system-configuration-for-specific-use-cases\n",
    "\n",
    "# 1. DeGirum Cloud Zoo inference:\n",
    "#zoo = dg.connect_model_zoo(\"dgcps://cs.degirum.com\", token=mytools.token_get())\n",
    "\n",
    "# 2. AIServer inference via IP address using models from DeGirum Cloud model zoo\n",
    "#zoo = dg.connect_model_zoo((\"192.168.0.7\", \"https://cs.degirum.com/degirum_com/public\"), token=mytools.token_get())\n",
    "\n",
    "# 3. AIServer inference via IP address using local model zoo\n",
    "#zoo = dg.connect_model_zoo(\"192.168.0.1\")\n",
    "\n",
    "# 4. ORCA board installed locally using models from DeGirum Cloud Model Zoo\n",
    "#zoo = dg.connect_model_zoo(\"https://cs.degirum.com/degirum_com/public\", token=mytools.token_get())\n",
    "\n",
    "# 5. Local inference with locally deployed model\n",
    "#zoo = dg.connect_model_zoo(\"full/path/to/model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6fcd6-6e59-4d49-b5cc-521d41c16f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some object detection AI model\n",
    "model = zoo.load_model(\"yolo_v5s_coco--512x512_quant_n2x_orca_1\")\n",
    "\n",
    "c = Composition();\n",
    "\n",
    "# create gizmos\n",
    "source = c.add(VideoSourceGizmo(camera_id)) # video source\n",
    "detection = c.add(AiSimpleGizmo(model)) # AI model\n",
    "display = c.add(VideoDisplayGizmo(\"Detection\", show_ai_overlay=True, show_fps=True)) # display\n",
    "\n",
    "# create pipeline\n",
    "source >> detection >> display\n",
    "\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eadf612-390e-4cd4-9dc3-94fd77b3869c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of pipelined AI inference\n",
    "\n",
    "Frames from the camera are supplied to the face detection model and then the mask classification model is applied for each detected face bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78dc52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg\n",
    "import mytools\n",
    "from mystreams import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9bf644",
   "metadata": {},
   "source": [
    "### Set inference option here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please uncomment and edit one of the following inference options to specify your system configuration case according to\n",
    "# https://cs.degirum.com/doc/0.5.0/degirum.html#system-configuration-for-specific-use-cases\n",
    "\n",
    "# 1. DeGirum Cloud Zoo inference:\n",
    "#zoo = dg.connect_model_zoo(\"dgcps://cs.degirum.com\", token=mytools.token_get())\n",
    "\n",
    "# 2. AIServer inference via IP address using models from DeGirum Cloud model zoo\n",
    "#zoo = dg.connect_model_zoo((\"192.168.0.7\", \"https://cs.degirum.com/degirum_com/public\"), token=mytools.token_get())\n",
    "\n",
    "# 3. AIServer inference via IP address using local model zoo\n",
    "#zoo = dg.connect_model_zoo(\"192.168.0.1\")\n",
    "\n",
    "# 4. ORCA board installed locally using models from DeGirum Cloud Model Zoo\n",
    "#zoo = dg.connect_model_zoo(\"https://cs.degirum.com/degirum_com/public\", token=mytools.token_get())\n",
    "\n",
    "# 5. Local inference with locally deployed model\n",
    "#zoo = dg.connect_model_zoo(\"full/path/to/model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2956b-4c31-4259-a58a-e16f05266ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load AI models\n",
    "face_model = zoo.load_model(\"yolo_v5s_face_det--512x512_quant_n2x_orca_1\")\n",
    "mask_model = zoo.load_model(\"mobilenet_v2_mask_yn_cls--224x224_float_n2x_orca_1\")\n",
    "face_model.overlay_show_probabilities = True\n",
    "\n",
    "class MaskDetectionGizmo(AiGizmoBase):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._cur_result = None\n",
    "        \n",
    "    def on_result(self, result):\n",
    "        \n",
    "        # here result.info contains StreamData object used for AI inference (because AiGizmoBase does it this way);\n",
    "        # and result.info.meta contains metainfo dictionary placed by AiObjectDetectionCroppingGizmo, \n",
    "        # because in our pipeline it is connected as a source of this gizmo\n",
    "        meta = result.info.meta\n",
    "        if \"original_result\" in meta: # new result\n",
    "            if self._cur_result is not None:\n",
    "                # send previous result\n",
    "                self.send_result(StreamData(self._cur_result.image, self._cur_result))                \n",
    "            self._cur_result = meta[\"original_result\"]\n",
    "        \n",
    "        if \"cropped_index\" in meta:\n",
    "            # apply mask presence/absence label\n",
    "            if len(result.results) > 0:\n",
    "                self._cur_result.results[meta[\"cropped_index\"]][\"label\"] = result.results[0][\"label\"]\n",
    "                self._cur_result.results[meta[\"cropped_index\"]][\"score\"] = result.results[0][\"score\"]\n",
    "\n",
    "c = Composition();\n",
    "\n",
    "# create gizmos\n",
    "source = c.add(VideoSourceGizmo(camera_id)) # video source\n",
    "face_detection = c.add(AiObjectDetectionCroppingGizmo([\"face\"], face_model)) # face detection gizmo, which outputs cropped images for all detected faces\n",
    "mask_detection = c.add(MaskDetectionGizmo(mask_model)) # mask detection AI model\n",
    "face_display = c.add(VideoDisplayGizmo(\"Faces\", show_ai_overlay=True, show_fps=True)) # display\n",
    "\n",
    "# create pipeline\n",
    "source >> face_detection >> mask_detection >> face_display\n",
    "\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3706c9-1246-4e2b-a3f7-edb247a303d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
