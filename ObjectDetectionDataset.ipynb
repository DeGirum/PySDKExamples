{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c15cb24",
   "metadata": {},
   "source": [
    "## AI Inference on image dataset retrieved from a cloud\n",
    "This notebook is an example how to use DeGirum PySDK to do AI inference of an image dataset.\n",
    "Image dataset is retrieved from the cloud using `fiftyone` API.\n",
    "\n",
    "#### This sample uses the following external packages, which need to be installed:\n",
    "1. **fiftyone**: `pip install fiftyone`\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you just need to uncomment **one** of the lines in the code below.\n",
    "\n",
    "You also need to specify your cloud API access token, cloud zoo URLs, and AI server hostname in [env.ini](env.ini) file, located in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01549d7c-2445-4007-8a89-ac0f3a864530",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Specify dataset parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34df11-cbc7-4b00-8994-794a4a6548b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify the name of desired dataset to retrieve;\n",
    "# see https://voxel51.com/docs/fiftyone/user_guide/dataset_zoo/datasets.html\n",
    "foz_dataset_name = \"coco-2017\"\n",
    "\n",
    "# specify list of class labels to retrieve; None for all classes\n",
    "foz_classes = None # [\"car\", \"cup\", \"person\"]\n",
    "\n",
    "# specify which splits to download (\"train\", \"validation\", \"test\")\n",
    "foz_splits = \"validation\"\n",
    "\n",
    "# specify # of samples in dataset to retrieve\n",
    "samples_num = 1000\n",
    "\n",
    "# specify the model to be used for inference\n",
    "model_name = \"yolo_v5s_coco--512x512_quant_n2x_orca1_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d310e-6491-4a6d-a675-76bc6744dd08",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Specify where do you want to run your inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e36bdd-1b97-4511-8edf-ebff67fe5fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import degirum as dg, mytools\n",
    "\n",
    "#\n",
    "# Please UNCOMMENT only ONE of the following lines to specify where to run AI inference\n",
    "#\n",
    "\n",
    "target = dg.CLOUD # <-- on the Cloud Platform\n",
    "# target = mytools.get_ai_server_hostname() # <-- on AI Server deployed in your LAN\n",
    "# target = dg.LOCAL # <-- on ORCA accelerator installed on this computer\n",
    "\n",
    "# connect to AI inference engine getting zoo URL and token from env.ini file\n",
    "zoo = dg.connect(target, mytools.get_cloud_zoo_url(), mytools.get_token())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12429d26-64b5-4a45-9b5d-9dad5ffd3222",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512335c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, IPython\n",
    "fo = mytools.import_fiftyone() # import 'fiftyone' package for dataset management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d329b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download dataset\n",
    "dataset = fo.zoo.load_zoo_dataset(\n",
    "    foz_dataset_name,\n",
    "    dataset_dir=\"./my-dataset\", \n",
    "    classes=foz_classes,\n",
    "    split=foz_splits,\n",
    "    max_samples=samples_num,\n",
    "    shuffle=True,\n",
    "    drop_existing_dataset=False)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476962b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "model = zoo.load_model(model_name)\n",
    "model.output_confidence_threshold = 0.1 # set low confidence threshold for proper statistics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796be79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Extracting dataset samples...\")\n",
    "all_samples = dataset.head(dataset.count()) # retrieve all dataset samples\n",
    "all_files = [s.filepath for s in all_samples]\n",
    "print(\"...done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7338279d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Running inference:\")\n",
    "progress = mytools.Progress(len(all_files))\n",
    "for n, res in enumerate(model.predict_batch(all_files)):\n",
    "    if model.image_backend == 'pil':\n",
    "        w, h = res.image.size\n",
    "    else: # opencv\n",
    "        w = res.image.shape[1]\n",
    "        h = res.image.shape[0]\n",
    "    \n",
    "    detections = []\n",
    "    for box in res.results:\n",
    "        # Convert to [top-left-x, top-left-y, width, height]\n",
    "        # in relative coordinates in [0, 1] x [0, 1]\n",
    "        x1, y1, x2, y2 = box[\"bbox\"]\n",
    "        rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
    "        detections.append(fo.Detection(label=box[\"label\"], bounding_box=rel_box, confidence=box[\"score\"]))\n",
    "    all_samples[n][\"predictions\"] = fo.Detections(detections=detections)\n",
    "    all_samples[n].save()\n",
    "    progress.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a70378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run evaluation on predictions\n",
    "eval_result = dataset.evaluate_detections(\"predictions\", classes=foz_classes, compute_mAP=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899c3bd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print some evaluation results\n",
    "print( f\"mAP = {eval_result.mAP():.2f}\\n\")\n",
    "eval_result.print_report(classes=foz_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec53574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
