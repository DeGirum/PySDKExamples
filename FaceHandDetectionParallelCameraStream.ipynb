{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "438aa03a",
   "metadata": {},
   "source": [
    "## Running two ML models at the same time\n",
    "This notebook is an example how to run two models side-by-side and combine results of both models. A video stream from a local camera is processed by the hand and face detection models. Combined result is then displayed.\n",
    "OpenCV is required to run this sample.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. [DeGirum Cloud Platform](cs.degirum.com),\n",
    "1. DeGirum-hosted AI server node shared via Peer-to-Peer VPN,\n",
    "1. AI server node hosted by you in your local network,\n",
    "1. AI server running on your local machine,\n",
    "1. DeGirum ORCA accelerator directly installed on your local machine.\n",
    "\n",
    "To try different options, you just need to change the `inference_option` in the code below.\n",
    "\n",
    "The script needs a web camera connected to the machine running this code. The `camera_index` also needs to be specified in the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed53050e-8e74-454f-b4eb-4883a8f02ca9",
   "metadata": {},
   "source": [
    "### Specify where do you want to run your inferences and camera index here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e9dd69-dcdc-4fc6-8c8d-0d8771eb5d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_option = 1  # <<< change it according to your needs selecting from the list in the header comment\n",
    "camera_index = 0      # camera index; 0 is default camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c0c86d-0e48-4116-9f7d-61dc1a08f8fa",
   "metadata": {},
   "source": [
    "### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d4cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import degirum as dg # import DeGirum PySDK\n",
    "import mytools, cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a980c204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference option = 'DeGirum Cloud Platform\n"
     ]
    }
   ],
   "source": [
    "# connect to model zoo according to selected inference option\n",
    "zoo = mytools.connect_model_zoo(inference_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33012fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models for DeGirum Orca AI accelerator\n",
    "# (change model name to \"...n2x_cpu_1\" to run it on CPU)\n",
    "hand_det_model = zoo.load_model(\"yolo_v5s_hand_det--512x512_quant_n2x_orca_1\")\n",
    "face_det_model = zoo.load_model(\"yolo_v5s_face_det--512x512_quant_n2x_orca_1\")\n",
    "\n",
    "# select OpenCV backend: needed to have overlay image in OpenCV format\n",
    "hand_det_model.image_backend = 'opencv'\n",
    "hand_det_model._model_parameters.InputImgFmt = ['JPEG']\n",
    "hand_det_model.input_numpy_colorspace = 'BGR'\n",
    "\n",
    "face_det_model.image_backend = 'opencv' \n",
    "face_det_model._model_parameters.InputImgFmt = ['JPEG']\n",
    "face_det_model.input_numpy_colorspace = 'BGR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57eccd95-e365-42d6-86d3-1e2e017744ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully opened video stream\n"
     ]
    }
   ],
   "source": [
    "# open video stream from local camera \n",
    "stream = mytools.open_video_stream(camera_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7465a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define iterator function, which returns frames from camera \n",
    "def source(idx):\n",
    "    # idx is the index of a buffer\n",
    "    N = 2 # number of buffers\n",
    "    bufs = [[]] * N\n",
    "    assert idx < N\n",
    "    while True:\n",
    "        if len(bufs[idx]) == 0: # this buffer is empty: get frame from camera and add to all buffers\n",
    "            ret, frame = stream.read()\n",
    "            if not ret:\n",
    "                raise Exception(\"Fail to capture camera frame. May be camera was opened by another notebook?\")            \n",
    "            for s in bufs:\n",
    "                s.insert(0, frame)\n",
    "        yield bufs[idx].pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d93242ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mytools.cv_loop():\n",
    "    # run hand and faces detection models on a camera stream side-by-side\n",
    "    for hands, faces in zip(hand_det_model.predict_batch(source(0)), face_det_model.predict_batch(source(1))):\n",
    "        hands._inference_results += faces._inference_results # combine inference results of two detection models\n",
    "        mytools.show(hands.image_overlay, \"Hands and Faces\") # show image overlay with combined results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61884355",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.release() # release camera stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427a008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
